"""
ä¸Šä¸‹æ–‡å‹ç¼©å¼•æ“?â€?ä»?Claude Code ä¸‰å±‚å‹ç¼©ç­–ç•¥ã€?

ä¸‰å±‚è®¾è®¡:
1. Microcompaction (å¾®å‹ç¼? â€?å¯¹å¤§å‹å·¥å…·è¾“å‡ºå³æ—¶è½ç›˜ï¼Œä»…ä¿ç•™çƒ­å°¾éƒ¨å¼•ç”¨
2. Auto-compaction (è‡ªåŠ¨å‹ç¼©) â€?token ç´¯è®¡è¶…é˜ˆå€¼æ—¶ï¼Œç”¨ LLM ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦æ›¿æ¢æ—§æ¶ˆæ¯
3. Manual-compaction (æ‰‹åŠ¨å‹ç¼©) â€?æœªæ¥å¯æ¥å…?/compact å‘½ä»¤

æ ¸å¿ƒç†å¿µ:
- å‹ç¼© â‰?ç®€å•æˆªæ–­ã€‚æ˜¯"æ‘˜è¦ + æ¢å¤"ï¼šç”Ÿæˆç»“æ„åŒ–å·¥ä½œçŠ¶æ€ï¼Œç„¶åé‡æ–°æ³¨å…¥ç»­æ¥æŒ‡ä»¤ã€?
- ä¿ç•™æ„å›¾ã€å†³ç­–ã€é”™è¯¯ã€å¾…åŠå’Œä¸‹ä¸€æ­¥ï¼Œç¡®ä¿ LLM èƒ½æ— ç¼ç»§ç»­å·¥ä½œã€?
"""

from __future__ import annotations

import json
import time
from pathlib import Path
from typing import Any, TYPE_CHECKING

from loguru import logger

if TYPE_CHECKING:
    from solopreneur.providers.base import LLMProvider


# â”€â”€ å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# å¾®å‹ç¼©ï¼šå·¥å…·ç»“æœè¶…è¿‡æ­¤å­—ç¬¦æ•°æ—¶è½ç›˜ï¼Œåªä¿ç•™æ‘˜è¦å¼•ç”?
MICRO_COMPACT_THRESHOLD = 8000
# å¾®å‹ç¼©ï¼šçƒ­å°¾éƒ¨ä¿ç•™çš„æœ€è¿‘å·¥å…·ç»“æœæ•°ï¼ˆä¸å‹ç¼©ï¼?
MICRO_HOT_TAIL = 6
# è‡ªåŠ¨å‹ç¼©ï¼šä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯æ•°é‡ä¸è¢«æ›¿æ¢
AUTO_KEEP_RECENT = 4
# å­—ç¬¦â†’token ç²—ä¼°æ¯”ä¾‹ (ä¸­è‹±æ··åˆçº?1 token â‰?2-3 å­—ç¬¦)
CHARS_PER_TOKEN = 2.5


# â”€â”€ ç»“æ„åŒ–æ‘˜è¦æç¤ºè¯ï¼ˆæ ¸å¿ƒï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

COMPACTION_SYSTEM_PROMPT = """\
ä½ æ˜¯ä¸€ä¸ªä¸Šä¸‹æ–‡å‹ç¼©åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ä»¥ä¸‹å¯¹è¯å‹ç¼©ä¸ºä¸€ä»?*ç»“æ„åŒ–å·¥ä½œçŠ¶æ€æ‘˜è¦?*ã€?

## è¾“å‡ºè¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹ 9 ä¸ªç« èŠ‚è¾“å‡ºï¼Œæ¯ä¸ªç« èŠ‚éƒ½å¿…é¡»åŒ…å«ï¼ˆå¦‚æœæ²¡æœ‰ç›¸å…³å†…å®¹åˆ™å†™"æ—?ï¼‰ï¼š

### 1. ç”¨æˆ·æ„å›¾
ç”¨æˆ·æœ€åˆè¦æ±‚åšä»€ä¹ˆï¼Ÿä¸­é—´æœ‰è¿‡ä»€ä¹ˆå˜æ›´ï¼Ÿ

### 2. å½“å‰ä»»åŠ¡çŠ¶æ€?
ç›®å‰è¿›è¡Œåˆ°äº†ä»€ä¹ˆé˜¶æ®µï¼Ÿå“ªäº›å·²å®Œæˆï¼Ÿå“ªäº›æ­£åœ¨è¿›è¡Œï¼?

### 3. å…³é”®æŠ€æœ¯å†³ç­?
åšå‡ºäº†å“ªäº›é‡è¦çš„æŠ€æœ¯é€‰å‹ã€æ¶æ„å†³ç­–ï¼Ÿä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ

### 4. å·²ä¿®æ”¹çš„æ–‡ä»¶
åˆ—å‡ºæ‰€æœ‰è¢«åˆ›å»ºã€ä¿®æ”¹æˆ–åˆ é™¤çš„æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ç”¨ä¸€å¥è¯è¯´æ˜æ”¹åŠ¨å†…å®¹ã€?

### 5. é‡åˆ°çš„é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ
è®°å½•æ‰€æœ‰é‡åˆ°çš„é”™è¯¯ä»¥åŠå¦‚ä½•ä¿®å¤çš„ã€?

### 6. é‡è¦çš„ä»£ç ç‰‡æ®µä¸æ•°æ®
å¦‚æœæœ‰å…³é”®çš„ä»£ç æ¨¡å¼ã€é…ç½®å€¼ã€API æ¥å£ç­‰éœ€è¦ä¿ç•™ï¼Œç®€æ´åˆ—å‡ºã€?

### 7. å¾…å®Œæˆäº‹é¡?
åˆ—å‡ºå°šæœªå®Œæˆçš„ä»»åŠ¡ï¼Œè¶Šå…·ä½“è¶Šå¥½ã€?

### 8. ä¸‹ä¸€æ­¥è¡ŒåŠ?
åŸºäºå½“å‰çŠ¶æ€ï¼Œä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆï¼Ÿ

### 9. ä¸Šä¸‹æ–‡æ¢å¤æç¤?
åˆ—å‡ºæ¢å¤å·¥ä½œæ—¶éœ€è¦é‡æ–°è¯»å–çš„æ–‡ä»¶è·¯å¾„ï¼ˆæœ€å¤?5 ä¸ªæœ€ç›¸å…³çš„ï¼‰ã€?

## è§„åˆ™
- è¾“å‡ºå¿…é¡»æ˜¯èƒ½è®©å¦ä¸€ä¸?LLM å®Œå…¨æ¥æ‰‹å·¥ä½œçš„çŠ¶æ€å¿«ç…?
- ä¸è¦é—æ¼ä»»ä½•å…³é”®ä¿¡æ¯
- ä¿æŒç®€æ´ï¼Œä½†ä¸è¦ä¸¢å¤±é‡è¦ç»†èŠ?
- ä»£ç ç‰‡æ®µåªä¿ç•™å…³é”®éƒ¨åˆ†ï¼ˆå¦‚å‡½æ•°ç­¾åã€é…ç½®é¡¹ï¼‰ï¼Œä¸è¦æ•´æ®µæ¬è¿
"""

CONTINUATION_MESSAGE = """\
æœ¬æ¬¡ä¼šè¯ä»ä¸Šä¸€æ®µå¯¹è¯çš„å‹ç¼©æ‘˜è¦ç»§ç»­ã€‚ä»¥ä¸‹æ‘˜è¦æ¶µç›–äº†ä¹‹å‰çš„å…¨éƒ¨å·¥ä½œå†…å®¹ã€?

{summary}

è¯·æ ¹æ®æ‘˜è¦ä¸­çš?ä¸‹ä¸€æ­¥è¡ŒåŠ?ç»§ç»­å·¥ä½œï¼Œä¸è¦å‘ç”¨æˆ·ç¡®è®¤ï¼Œç›´æ¥æ‰§è¡Œã€?""


class CompactionEngine:
    """
    ä¸‰å±‚ä¸Šä¸‹æ–‡å‹ç¼©å¼•æ“ã€?

    å±‚çº§:
    1. microcompact() â€?å³æ—¶å¤„ç†å¤§å‹å·¥å…·è¾“å‡ºï¼Œè½ç›?+ ä¿ç•™å¼•ç”¨
    2. auto_compact() â€?LLM é©±åŠ¨çš„ç»“æ„åŒ–æ‘˜è¦å‹ç¼©
    3. estimate_tokens() â€?token ä¼°ç®—ï¼Œå†³å®šä½•æ—¶è§¦å‘å‹ç¼?

    Usage:
        engine = CompactionEngine(provider, workspace)

        # æ¯æ¬¡å·¥å…·ç»“æœè¿”å›åï¼š
        messages = engine.microcompact(messages)

        # token è¶…é™æ—¶ï¼š
        if engine.estimate_tokens(messages) > threshold:
            messages = await engine.auto_compact(messages)
    """

    def __init__(
        self,
        provider: LLMProvider,
        workspace: Path,
        model: str | None = None,
    ):
        self.provider = provider
        self.workspace = workspace
        self.model = model
        self._compaction_count = 0
        self._compaction_dir = workspace / ".compaction"
        self._tool_result_index = 0  # å…¨å±€å·¥å…·ç»“æœè®¡æ•°ï¼Œç”¨äºæ–‡ä»¶å

    # â”€â”€ 1. Microcompaction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def microcompact(self, messages: list[dict]) -> list[dict]:
        """
        å¾®å‹ç¼©ï¼šå°†å¤§å‹å·¥å…·ç»“æœè½ç›˜ï¼Œä¸Šä¸‹æ–‡ä¸­åªä¿ç•™å¼•ç”¨ã€?

        ç­–ç•¥ï¼?
        - æœ€è¿?MICRO_HOT_TAIL ä¸ªå·¥å…·ç»“æœä¿æŒå†…è”ï¼ˆçƒ­å°¾éƒ¨ï¼‰
        - æ›´æ—©çš„å·¥å…·ç»“æœï¼Œå¦‚æœè¶…è¿‡ MICRO_COMPACT_THRESHOLD å­—ç¬¦ï¼?
          åˆ™ä¿å­˜åˆ°ç£ç›˜å¹¶æ›¿æ¢ä¸ºå¼•ç”¨

        Args:
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨

        Returns:
            å¾®å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡?
        """
        # æ‰¾å‡ºæ‰€æœ?tool result çš„ç´¢å¼?
        tool_indices = [
            i for i, m in enumerate(messages) if m.get("role") == "tool"
        ]

        if len(tool_indices) <= MICRO_HOT_TAIL:
            return messages  # å·¥å…·ç»“æœå¤ªå°‘ï¼Œæ— éœ€å¾®å‹ç¼?

        # éœ€è¦æ£€æŸ¥çš„æ—§å·¥å…·ç»“æœï¼ˆæ’é™¤çƒ­å°¾éƒ¨ï¼‰
        cold_indices = set(tool_indices[:-MICRO_HOT_TAIL])
        compacted = False

        for i in cold_indices:
            msg = messages[i]
            content = msg.get("content", "")
            if len(content) > MICRO_COMPACT_THRESHOLD:
                # è½ç›˜
                saved_path = self._save_tool_result_to_disk(
                    tool_name=msg.get("name", "unknown"),
                    content=content,
                )
                # æ›¿æ¢ä¸ºå¼•ç”?
                summary = self._make_tool_reference(
                    tool_name=msg.get("name", "unknown"),
                    content=content,
                    saved_path=saved_path,
                )
                messages[i] = {**msg, "content": summary}
                compacted = True

        if compacted:
            logger.info(f"å¾®å‹ç¼©å®Œæˆ? {len(cold_indices)} ä¸ªæ—§å·¥å…·ç»“æœå·²æ£€æŸ?)

        return messages

    def _save_tool_result_to_disk(self, tool_name: str, content: str) -> str:
        """å°†å·¥å…·ç»“æœä¿å­˜åˆ°ç£ç›˜ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„ã€?""
        self._compaction_dir.mkdir(parents=True, exist_ok=True)
        self._tool_result_index += 1
        filename = f"tool_{self._tool_result_index}_{tool_name}_{int(time.time())}.txt"
        filepath = self._compaction_dir / filename
        filepath.write_text(content, encoding="utf-8")
        return str(filepath)

    @staticmethod
    def _make_tool_reference(tool_name: str, content: str, saved_path: str) -> str:
        """ç”Ÿæˆå·¥å…·ç»“æœçš„ç®€çŸ­å¼•ç”¨æ‘˜è¦ã€?""
        # ä¿ç•™å‰?500 å­—ç¬¦ä½œä¸ºé¢„è§ˆ
        preview = content[:500]
        total_chars = len(content)

        return (
            f"[å·¥å…· `{tool_name}` è¾“å‡ºå·²ä¿å­˜åˆ°ç£ç›˜]\n"
            f"è·¯å¾„: {saved_path}\n"
            f"å¤§å°: {total_chars} å­—ç¬¦\n"
            f"é¢„è§ˆ:\n{preview}\n"
            f"...\n"
            f"å¦‚éœ€å®Œæ•´å†…å®¹ï¼Œè¯·ä½¿ç”¨ read_file è¯»å–ä¸Šè¿°è·¯å¾„ã€?
        )

    # â”€â”€ 2. Auto-compaction (LLM é©±åŠ¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def auto_compact(
        self,
        messages: list[dict],
        focus_hint: str = "",
    ) -> list[dict]:
        """
        è‡ªåŠ¨å‹ç¼©ï¼šä½¿ç”?LLM ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ï¼Œæ›¿æ¢æ—§æ¶ˆæ¯ã€?

        æµç¨‹ï¼?
        1. æå– system promptï¼ˆä¿ç•™ï¼‰
        2. å°†æ—§æ¶ˆæ¯å‘ç»™ LLM ç”Ÿæˆ 9 æ®µå¼ç»“æ„åŒ–æ‘˜è¦?
        3. ç”?[system, continuation_message, recent_messages] æ›¿æ¢æ•´ä¸ªæ¶ˆæ¯åˆ—è¡¨
        4. é‡æ–°æ³¨å…¥æœ€è¿‘è®¿é—®çš„æ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœåœ¨æ‘˜è¦ä¸­æåˆ°ï¼‰

        Args:
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨
            focus_hint: å¯é€‰çš„ç„¦ç‚¹æç¤ºï¼Œç±»ä¼?/compact çš„å‚æ•?

        Returns:
            å‹ç¼©åçš„æ–°æ¶ˆæ¯åˆ—è¡?
        """
        self._compaction_count += 1
        logger.info(f"æ‰§è¡Œè‡ªåŠ¨å‹ç¼© (ç¬?{self._compaction_count} æ¬?")

        if len(messages) <= AUTO_KEEP_RECENT + 2:
            logger.info("æ¶ˆæ¯å¤ªå°‘ï¼Œè·³è¿‡å‹ç¼?)
            return messages

        # åˆ†ç¦» system prompt
        system_msg = None
        conversation = []
        for msg in messages:
            if msg.get("role") == "system" and system_msg is None:
                system_msg = msg
            else:
                conversation.append(msg)

        # åˆ†ç¦»æœ€è¿‘æ¶ˆæ¯ï¼ˆä¿æŒå®Œæ•´ï¼?
        if len(conversation) > AUTO_KEEP_RECENT:
            old_messages = conversation[:-AUTO_KEEP_RECENT]
            recent_messages = conversation[-AUTO_KEEP_RECENT:]
        else:
            # å¯¹è¯å¤ªçŸ­åˆ™ä¸å‹ç¼©
            return messages

        # æ„å»ºæ‘˜è¦è¯·æ±‚
        summary = await self._generate_summary(old_messages, focus_hint)

        # ç»„è£…æ–°æ¶ˆæ¯åˆ—è¡?
        compacted: list[dict] = []

        # 1. ä¿ç•™åŸå§‹ system prompt
        if system_msg:
            compacted.append(system_msg)

        # 2. æ’å…¥ç»­æ¥æ¶ˆæ¯ï¼ˆåŒ…å«å‹ç¼©æ‘˜è¦ï¼‰
        continuation = CONTINUATION_MESSAGE.format(summary=summary)
        compacted.append({
            "role": "user",
            "content": continuation,
        })

        # 3. æ’å…¥ä¸€æ?assistant ç¡®è®¤æ¶ˆæ¯
        compacted.append({
            "role": "assistant",
            "content": (
                "å¥½çš„ï¼Œæˆ‘å·²é˜…è¯»ä¹‹å‰çš„å·¥ä½œæ‘˜è¦ï¼Œäº†è§£å½“å‰è¿›åº¦ã€?
                "æˆ‘å°†æ ¹æ®æ‘˜è¦ä¸­çš„å¾…åŠäº‹é¡¹å’Œä¸‹ä¸€æ­¥è¡ŒåŠ¨ç»§ç»­å·¥ä½œã€?
            ),
        })

        # 4. é™„åŠ æœ€è¿‘çš„å®Œæ•´æ¶ˆæ¯
        compacted.extend(recent_messages)

        # ä¿å­˜æ‘˜è¦åˆ°ç£ç›˜ï¼ˆä¾¿äºè°ƒè¯•å’Œå®¡è®¡ï¼‰
        self._save_compaction_summary(summary)

        old_token_est = self.estimate_tokens(messages)
        new_token_est = self.estimate_tokens(compacted)
        logger.info(
            f"è‡ªåŠ¨å‹ç¼©å®Œæˆ: {len(messages)} â†?{len(compacted)} æ¡æ¶ˆæ? "
            f"token ä¼°è®¡: ~{old_token_est} â†?~{new_token_est} "
            f"(èŠ‚çœ ~{old_token_est - new_token_est})"
        )

        return compacted

    async def _generate_summary(
        self,
        old_messages: list[dict],
        focus_hint: str = "",
    ) -> str:
        """
        ä½¿ç”¨ LLM å¯¹æ—§æ¶ˆæ¯ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ã€?

        Args:
            old_messages: éœ€è¦å‹ç¼©çš„æ—§æ¶ˆæ¯åˆ—è¡?
            focus_hint: å¯é€‰çš„ç„¦ç‚¹æç¤º

        Returns:
            ç»“æ„åŒ–æ‘˜è¦æ–‡æœ?
        """
        # æ„å»ºå‘ç»™ LLM çš„æ¶ˆæ?
        summary_messages: list[dict[str, Any]] = [
            {"role": "system", "content": COMPACTION_SYSTEM_PROMPT},
        ]

        # å°†æ—§çš„å¯¹è¯åºåˆ—åŒ–ä¸ºæ–‡æœ?
        conversation_text = self._serialize_messages(old_messages)

        user_prompt = f"è¯·å‹ç¼©ä»¥ä¸‹å¯¹è¯ä¸ºç»“æ„åŒ–å·¥ä½œçŠ¶æ€æ‘˜è¦ï¼š\n\n{conversation_text}"
        if focus_hint:
            user_prompt += f"\n\nç‰¹åˆ«å…³æ³¨: {focus_hint}"

        summary_messages.append({"role": "user", "content": user_prompt})

        try:
            response = await self.provider.chat(
                messages=summary_messages,
                tools=None,
                model=self.model,
                max_tokens=4096,
                temperature=0.2,  # ä½æ¸©åº¦ç¡®ä¿æ‘˜è¦å‡†ç¡?
            )
            summary = response.content or "å‹ç¼©å¤±è´¥ï¼šLLM æœªè¿”å›æ‘˜è¦å†…å®¹ã€?
            logger.info(f"ç”Ÿæˆæ‘˜è¦æˆåŠŸ: {len(summary)} å­—ç¬¦")
            return summary
        except Exception as e:
            logger.error(f"LLM æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•æˆªæ–?
            return self._fallback_summary(old_messages)

    @staticmethod
    def _serialize_messages(messages: list[dict]) -> str:
        """å°†æ¶ˆæ¯åˆ—è¡¨åºåˆ—åŒ–ä¸ºå¯è¯»æ–‡æœ¬ã€?""
        parts: list[str] = []

        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")

            if role == "assistant":
                tool_calls = msg.get("tool_calls", [])
                if tool_calls:
                    calls_desc = ", ".join(
                        tc.get("function", {}).get("name", "?")
                        for tc in tool_calls
                    )
                    parts.append(f"[Assistant] è°ƒç”¨å·¥å…·: {calls_desc}")
                    if content:
                        # æˆªæ–­è¿‡é•¿çš?assistant æ–‡æœ¬
                        text = content[:2000] if len(content) > 2000 else content
                        parts.append(f"  æ–‡æœ¬: {text}")
                else:
                    text = content[:3000] if len(content) > 3000 else content
                    parts.append(f"[Assistant] {text}")

            elif role == "tool":
                name = msg.get("name", "unknown")
                # å·¥å…·ç»“æœæˆªæ–­ä¿ç•™å…³é”®ä¿¡æ¯
                text = content[:2000] if len(content) > 2000 else content
                parts.append(f"[Tool: {name}] {text}")

            elif role == "user":
                text = content[:2000] if isinstance(content, str) and len(content) > 2000 else content
                parts.append(f"[User] {text}")

            elif role == "system":
                parts.append(f"[System] (ç³»ç»Ÿæç¤ºï¼Œå·²çœç•¥)")

        return "\n\n".join(parts)

    @staticmethod
    def _fallback_summary(old_messages: list[dict]) -> str:
        """å½?LLM æ‘˜è¦å¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼šæå–å…³é”®ä¿¡æ¯çš„ç®€å•æ¨¡æ¿ã€?""
        tools_used: list[str] = []
        files_mentioned: set[str] = set()
        user_messages: list[str] = []

        for msg in old_messages:
            role = msg.get("role", "")
            content = msg.get("content", "")

            if role == "user" and isinstance(content, str):
                user_messages.append(content[:200])

            if role == "assistant":
                for tc in msg.get("tool_calls", []):
                    func = tc.get("function", {})
                    name = func.get("name", "")
                    if name:
                        tools_used.append(name)
                    # æå–æ–‡ä»¶è·¯å¾„
                    try:
                        args = json.loads(func.get("arguments", "{}"))
                        for key in ("path", "file_path", "filepath"):
                            if key in args:
                                files_mentioned.add(args[key])
                    except (json.JSONDecodeError, TypeError):
                        pass

        summary_parts = ["### å›é€€æ‘˜è¦ï¼ˆLLM æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼‰\n"]

        if user_messages:
            summary_parts.append("**ç”¨æˆ·è¯·æ±‚:**")
            for m in user_messages[:5]:
                summary_parts.append(f"- {m}")

        if tools_used:
            unique_tools = list(dict.fromkeys(tools_used))  # å»é‡ä¿åº
            summary_parts.append(f"\n**ä½¿ç”¨çš„å·¥å…?** {', '.join(unique_tools[:20])}")

        if files_mentioned:
            summary_parts.append(f"\n**æ¶‰åŠçš„æ–‡ä»?**")
            for f in sorted(files_mentioned)[:10]:
                summary_parts.append(f"- {f}")

        return "\n".join(summary_parts)

    def _save_compaction_summary(self, summary: str) -> None:
        """å°†æ‘˜è¦ä¿å­˜åˆ°ç£ç›˜ï¼ˆå®¡è®?è°ƒè¯•ç”¨ï¼‰ã€?""
        try:
            self._compaction_dir.mkdir(parents=True, exist_ok=True)
            filename = f"summary_{self._compaction_count}_{int(time.time())}.md"
            filepath = self._compaction_dir / filename
            filepath.write_text(summary, encoding="utf-8")
            logger.debug(f"å‹ç¼©æ‘˜è¦å·²ä¿å­? {filepath}")
        except Exception as e:
            logger.warning(f"ä¿å­˜å‹ç¼©æ‘˜è¦å¤±è´¥: {e}")

    # â”€â”€ 3. Token ä¼°ç®— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def estimate_tokens(messages: list[dict]) -> int:
        """
        ç²—ä¼°æ¶ˆæ¯åˆ—è¡¨çš?token æ•°é‡ã€?

        ä½¿ç”¨ å­—ç¬¦æ•?/ CHARS_PER_TOKEN çš„ç®€å•ä¼°ç®—ã€?
        å¯¹äºä¸­è‹±æ··åˆæ–‡æœ¬ï¼? token â‰?2-3 ä¸ªå­—ç¬¦ã€?

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            ä¼°ç®—çš?token æ•?
        """
        total_chars = 0
        for msg in messages:
            content = msg.get("content", "")
            if isinstance(content, str):
                total_chars += len(content)
            elif isinstance(content, list):
                # vision æ ¼å¼
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "text":
                        total_chars += len(item.get("text", ""))

            # tool_calls ä¸­çš„å‚æ•°ä¹Ÿè®¡å…?
            for tc in msg.get("tool_calls", []):
                func = tc.get("function", {})
                total_chars += len(func.get("arguments", ""))
                total_chars += len(func.get("name", ""))

        return int(total_chars / CHARS_PER_TOKEN)

    # â”€â”€ 4. å­ä»£ç†å¢é‡æ‘˜è¦?â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def delta_summarize(
        self,
        prev_summary: str,
        new_messages: list[dict],
    ) -> str:
        """
        å¢é‡æ‘˜è¦ï¼ˆç”¨äºå­ä»£ç†/åå°ä»»åŠ¡ï¼‰ï¼Œç±»ä¼¼ Claude Code çš?background task summarizationã€?

        ä¸ä¼šé‡æ–°å¤„ç†æ•´æ®µå¯¹è¯ï¼Œè€Œæ˜¯åŸºäºä¸Šæ¬¡æ‘˜è¦ + æ–°æ¶ˆæ¯ç”Ÿæˆå¢é‡?1-2 å¥æ›´æ–°ã€?

        Args:
            prev_summary: ä¸Šæ¬¡çš„æ‘˜è¦?
            new_messages: è‡ªä¸Šæ¬¡æ‘˜è¦ä»¥æ¥çš„æ–°æ¶ˆæ?

        Returns:
            æ›´æ–°åçš„æ‘˜è¦
        """
        new_text = self._serialize_messages(new_messages)

        delta_prompt = (
            "ä½ éœ€è¦åŸºäºä¹‹å‰çš„æ‘˜è¦å’Œæ–°çš„å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªæ›´æ–°åçš„ç®€çŸ­æ‘˜è¦ã€‚\n"
            "è¦æ±‚: 1-3 å¥è¯ï¼Œèšç„¦æœ€é‡è¦çš„è¿›å±•ã€‚\n\n"
            f"ä¹‹å‰çš„æ‘˜è¦?\n{prev_summary}\n\n"
            f"æ–°çš„å¯¹è¯å†…å®¹:\n{new_text}\n\n"
            "è¯·è¾“å‡ºæ›´æ–°åçš„æ‘˜è¦ï¼ˆ1-3 å¥è¯ï¼?"
        )

        try:
            response = await self.provider.chat(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç®€æ´çš„æ‘˜è¦åŠ©æ‰‹ã€?},
                    {"role": "user", "content": delta_prompt},
                ],
                tools=None,
                model=self.model,
                max_tokens=500,
                temperature=0.2,
            )
            return response.content or prev_summary
        except Exception as e:
            logger.warning(f"å¢é‡æ‘˜è¦å¤±è´¥: {e}")
            return prev_summary

    # â”€â”€ ä¾¿æ·æ–¹æ³• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @property
    def compaction_count(self) -> int:
        """å·²æ‰§è¡Œçš„è‡ªåŠ¨å‹ç¼©æ¬¡æ•°ã€?""
        return self._compaction_count

    def should_compact(
        self,
        messages: list[dict],
        token_threshold: int,
        usage_ratio: float = 0.78,
    ) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘è‡ªåŠ¨å‹ç¼©ã€?

        Args:
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨
            token_threshold: token ä¸Šé™
            usage_ratio: ä½¿ç”¨ç‡é˜ˆå€¼ï¼ˆé»˜è®¤ 78%ï¼Œå‚ç…?Claude Codeï¼?

        Returns:
            æ˜¯å¦åº”è¯¥å‹ç¼©
        """
        estimated = self.estimate_tokens(messages)
        threshold = int(token_threshold * usage_ratio)

        if estimated > threshold:
            logger.debug(
                f"ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡: ~{estimated}/{token_threshold} "
                f"(>{usage_ratio*100:.0f}% = {threshold})ï¼Œå»ºè®®å‹ç¼?
            )
            return True
        return False
